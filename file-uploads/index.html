
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../extending/">
      
      
        <link rel="next" href="../installation/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>File Upload System - Ragdoll Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#file-upload-system" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Ragdoll Documentation" class="md-header__button md-logo" aria-label="Ragdoll Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ragdoll Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              File Upload System
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Ragdoll Documentation" class="md-nav__button md-logo" aria-label="Ragdoll Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Ragdoll Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ragdoll Documentation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api-client/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Client API Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Jobs Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Models Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api-services/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Services Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Architecture Overview
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../background-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Background Processing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Configuration Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../database-schema/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Database Schema
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Production Deployment Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Development Setup
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../document-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Document Processing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding-system/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embedding System
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../environment-variables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Environment Variables Reference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../extending/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Extending the System
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    File Upload System
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    File Upload System
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#shrine-based-production-file-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Shrine-based Production File Handling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shrine-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Shrine Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Shrine Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Core Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storage-backend-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Backend Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#content-specific-uploaders" class="md-nav__link">
    <span class="md-ellipsis">
      Content-Specific Uploaders
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#processing-pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Pipelines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported-file-types" class="md-nav__link">
    <span class="md-ellipsis">
      Supported File Types
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Supported File Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-documents" class="md-nav__link">
    <span class="md-ellipsis">
      Text Documents
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-files" class="md-nav__link">
    <span class="md-ellipsis">
      Image Files
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-files" class="md-nav__link">
    <span class="md-ellipsis">
      Audio Files
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#file-validation" class="md-nav__link">
    <span class="md-ellipsis">
      File Validation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="File Validation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layer-validation-system" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layer Validation System
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specialized-validation-rules" class="md-nav__link">
    <span class="md-ellipsis">
      Specialized Validation Rules
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#security-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Security Integration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#storage-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Storage Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#local-filesystem-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Local Filesystem Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amazon-s3-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Amazon S3 Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#google-cloud-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Google Cloud Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#azure-blob-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Azure Blob Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cdn-integration" class="md-nav__link">
    <span class="md-ellipsis">
      CDN Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-storage-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Storage Strategy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#file-processing-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      File Processing Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="File Processing Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#processing-workflow-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Workflow Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-1-file-upload-and-temporary-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 1: File Upload and Temporary Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-2-validation-and-security-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 2: Validation and Security Checks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-3-metadata-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 3: Metadata Extraction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-4-content-processing-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 4: Content Processing and Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-5-permanent-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 5: Permanent Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-6-database-record-creation" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 6: Database Record Creation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-monitoring-and-error-recovery" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Monitoring and Error Recovery
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#security-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Security Considerations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Security Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layered-security-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layered Security Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#file-type-validation" class="md-nav__link">
    <span class="md-ellipsis">
      File Type Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#malware-and-content-scanning" class="md-nav__link">
    <span class="md-ellipsis">
      Malware and Content Scanning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#access-control-and-authorization" class="md-nav__link">
    <span class="md-ellipsis">
      Access Control and Authorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encryption-at-rest" class="md-nav__link">
    <span class="md-ellipsis">
      Encryption at Rest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#security-audit-and-logging" class="md-nav__link">
    <span class="md-ellipsis">
      Security Audit and Logging
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation &amp; Setup
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../llm-integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Integration
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../metadata-schemas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Metadata Schemas
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../monitoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Monitoring &amp; Analytics
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-modal/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multi-Modal Architecture
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../performance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Performance Tuning
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../quick-start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quick Start Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../search-analytics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Search &amp; Analytics
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../security/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Security Considerations
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Testing Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../troubleshooting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Troubleshooting
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#shrine-based-production-file-handling" class="md-nav__link">
    <span class="md-ellipsis">
      Shrine-based Production File Handling
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shrine-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Shrine Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Shrine Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#core-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Core Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#storage-backend-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Backend Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#content-specific-uploaders" class="md-nav__link">
    <span class="md-ellipsis">
      Content-Specific Uploaders
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#processing-pipelines" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Pipelines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported-file-types" class="md-nav__link">
    <span class="md-ellipsis">
      Supported File Types
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Supported File Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-documents" class="md-nav__link">
    <span class="md-ellipsis">
      Text Documents
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-files" class="md-nav__link">
    <span class="md-ellipsis">
      Image Files
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#audio-files" class="md-nav__link">
    <span class="md-ellipsis">
      Audio Files
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#file-validation" class="md-nav__link">
    <span class="md-ellipsis">
      File Validation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="File Validation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layer-validation-system" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layer Validation System
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specialized-validation-rules" class="md-nav__link">
    <span class="md-ellipsis">
      Specialized Validation Rules
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#security-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Security Integration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#storage-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Storage Configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Storage Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#local-filesystem-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Local Filesystem Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#amazon-s3-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Amazon S3 Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#google-cloud-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Google Cloud Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#azure-blob-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Azure Blob Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cdn-integration" class="md-nav__link">
    <span class="md-ellipsis">
      CDN Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hybrid-storage-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      Hybrid Storage Strategy
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#file-processing-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      File Processing Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="File Processing Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#processing-workflow-overview" class="md-nav__link">
    <span class="md-ellipsis">
      Processing Workflow Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-1-file-upload-and-temporary-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 1: File Upload and Temporary Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-2-validation-and-security-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 2: Validation and Security Checks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-3-metadata-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 3: Metadata Extraction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-4-content-processing-and-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 4: Content Processing and Analysis
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-5-permanent-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 5: Permanent Storage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stage-6-database-record-creation" class="md-nav__link">
    <span class="md-ellipsis">
      Stage 6: Database Record Creation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipeline-monitoring-and-error-recovery" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline Monitoring and Error Recovery
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#security-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Security Considerations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Security Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-layered-security-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Layered Security Architecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#file-type-validation" class="md-nav__link">
    <span class="md-ellipsis">
      File Type Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#malware-and-content-scanning" class="md-nav__link">
    <span class="md-ellipsis">
      Malware and Content Scanning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#access-control-and-authorization" class="md-nav__link">
    <span class="md-ellipsis">
      Access Control and Authorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encryption-at-rest" class="md-nav__link">
    <span class="md-ellipsis">
      Encryption at Rest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#security-audit-and-logging" class="md-nav__link">
    <span class="md-ellipsis">
      Security Audit and Logging
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="file-upload-system">File Upload System</h1>
<p>Ragdoll implements a robust file upload and management system using the Shrine gem, providing secure, scalable file handling with multi-modal content support. The system handles documents, images, and audio files through a unified interface with comprehensive validation and processing capabilities.</p>
<h2 id="shrine-based-production-file-handling">Shrine-based Production File Handling</h2>
<p>The file upload system is built around Shrine's flexible architecture, offering:</p>
<ul>
<li><strong>Multi-Modal Support</strong>: Dedicated uploaders for text documents, images, and audio files</li>
<li><strong>Storage Flexibility</strong>: Configurable backends (filesystem, S3, Google Cloud, Azure)</li>
<li><strong>Security Focus</strong>: Comprehensive file validation, MIME type checking, and size limits</li>
<li><strong>Processing Pipeline</strong>: Integration with content extraction and embedding generation</li>
<li><strong>Metadata Extraction</strong>: Automatic file property detection and storage</li>
<li><strong>Production Ready</strong>: Designed for high-volume, concurrent file processing</li>
</ul>
<h2 id="shrine-integration">Shrine Integration</h2>
<p>Shrine provides the foundation for all file operations in Ragdoll, with specialized configurations for different content types.</p>
<h3 id="core-configuration">Core Configuration</h3>
<pre><code class="language-ruby"># lib/ragdoll/core/shrine_config.rb
require &quot;shrine&quot;
require &quot;shrine/storage/file_system&quot;

# Configure Shrine with filesystem storage
Shrine.storages = {
  cache: Shrine::Storage::FileSystem.new(&quot;tmp/uploads&quot;, prefix: &quot;cache&quot;),
  store: Shrine::Storage::FileSystem.new(&quot;uploads&quot;)
}

# Essential plugins for Ragdoll functionality
Shrine.plugin :activerecord           # ActiveRecord integration
Shrine.plugin :cached_attachment_data # Handle cached file data
Shrine.plugin :restore_cached_data    # Restore cached attachments
Shrine.plugin :rack_file             # Handle Rack file uploads
Shrine.plugin :validation_helpers     # File validation utilities
Shrine.plugin :determine_mime_type    # Automatic MIME type detection
</code></pre>
<h3 id="storage-backend-configuration">Storage Backend Configuration</h3>
<p><strong>Filesystem Storage (Development/Small Scale):</strong></p>
<pre><code class="language-ruby"># Basic filesystem configuration
Shrine.storages = {
  cache: Shrine::Storage::FileSystem.new(&quot;tmp/uploads&quot;, prefix: &quot;cache&quot;),
  store: Shrine::Storage::FileSystem.new(&quot;public/uploads&quot;)
}

# With custom directory structure
Shrine.storages = {
  cache: Shrine::Storage::FileSystem.new(
    &quot;tmp/ragdoll_cache&quot;, 
    prefix: &quot;cache&quot;,
    permissions: 0644
  ),
  store: Shrine::Storage::FileSystem.new(
    &quot;storage/ragdoll_files&quot;,
    prefix: &quot;files&quot;,
    permissions: 0644
  )
}
</code></pre>
<p><strong>Amazon S3 Storage (Production Recommended):</strong></p>
<pre><code class="language-ruby"># Gemfile
gem &quot;aws-sdk-s3&quot;, &quot;~&gt; 1.14&quot;

# Configuration
require &quot;shrine/storage/s3&quot;

Shrine.storages = {
  cache: Shrine::Storage::S3.new(
    bucket: ENV['S3_CACHE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
    prefix: &quot;ragdoll/cache&quot;
  ),
  store: Shrine::Storage::S3.new(
    bucket: ENV['S3_STORAGE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
    prefix: &quot;ragdoll/files&quot;,
    public: false  # Private files for security
  )
}

# S3-specific plugins
Shrine.plugin :presign_endpoint  # Generate presigned URLs
Shrine.plugin :upload_endpoint   # Direct uploads to S3
</code></pre>
<p><strong>Google Cloud Storage:</strong></p>
<pre><code class="language-ruby"># Gemfile
gem &quot;google-cloud-storage&quot;, &quot;~&gt; 1.11&quot;

# Configuration
require &quot;shrine/storage/google_cloud_storage&quot;

Shrine.storages = {
  cache: Shrine::Storage::GoogleCloudStorage.new(
    bucket: ENV['GCS_CACHE_BUCKET'],
    project: ENV['GOOGLE_CLOUD_PROJECT'],
    credentials: ENV['GOOGLE_CLOUD_KEYFILE'],
    prefix: &quot;ragdoll/cache&quot;
  ),
  store: Shrine::Storage::GoogleCloudStorage.new(
    bucket: ENV['GCS_STORAGE_BUCKET'],
    project: ENV['GOOGLE_CLOUD_PROJECT'],
    credentials: ENV['GOOGLE_CLOUD_KEYFILE'],
    prefix: &quot;ragdoll/files&quot;
  )
}
</code></pre>
<h3 id="content-specific-uploaders">Content-Specific Uploaders</h3>
<p>Ragdoll defines specialized uploaders for different content types:</p>
<pre><code class="language-ruby"># File uploader for documents (PDF, DOCX, TXT, etc.)
class FileUploader &lt; Shrine
  plugin :validation_helpers
  plugin :determine_mime_type
  plugin :add_metadata

  # Add custom metadata extraction
  add_metadata :custom_properties do |io|
    {
      original_filename: extract_filename(io),
      file_signature: calculate_file_signature(io),
      processing_metadata: extract_processing_hints(io)
    }
  end

  Attacher.validate do
    validate_max_size 50.megabytes
    validate_mime_type %w[
      application/pdf
      application/vnd.openxmlformats-officedocument.wordprocessingml.document
      text/plain
      text/html
      text/markdown
      application/json
      application/rtf
      application/msword
    ]
    validate_extension %w[pdf docx txt html md json rtf doc]
  end

  private

  def extract_filename(io)
    io.respond_to?(:original_filename) ? io.original_filename : nil
  end

  def calculate_file_signature(io)
    require 'digest'
    Digest::SHA256.hexdigest(io.read).tap { io.rewind }
  end
end

# Image uploader for visual content
class ImageUploader &lt; Shrine
  plugin :validation_helpers
  plugin :determine_mime_type
  plugin :store_dimensions  # Extract image dimensions
  plugin :add_metadata

  add_metadata :image_analysis do |io|
    {
      color_profile: extract_color_profile(io),
      has_transparency: detect_transparency(io),
      estimated_quality: assess_image_quality(io)
    }
  end

  Attacher.validate do
    validate_max_size 10.megabytes
    validate_mime_type %w[
      image/jpeg
      image/png
      image/gif
      image/webp
      image/bmp
      image/tiff
      image/svg+xml
    ]
    validate_extension %w[jpg jpeg png gif webp bmp tiff svg]

    # Custom validations
    validate :acceptable_resolution
    validate :safe_image_content
  end

  private

  def acceptable_resolution
    return unless file

    width, height = file[:metadata][&quot;width&quot;], file[:metadata][&quot;height&quot;]
    if width &amp;&amp; height
      total_pixels = width * height
      errors &lt;&lt; &quot;Image resolution too high (#{total_pixels} pixels)&quot; if total_pixels &gt; 50_000_000
      errors &lt;&lt; &quot;Image too small (#{width}x#{height})&quot; if width &lt; 10 || height &lt; 10
    end
  end
end

# Audio uploader for audio content
class AudioUploader &lt; Shrine
  plugin :validation_helpers
  plugin :determine_mime_type
  plugin :add_metadata

  add_metadata :audio_properties do |io|
    {
      duration: extract_audio_duration(io),
      sample_rate: extract_sample_rate(io),
      channels: extract_channel_count(io),
      bitrate: extract_bitrate(io)
    }
  end

  Attacher.validate do
    validate_max_size 100.megabytes
    validate_mime_type %w[
      audio/mpeg
      audio/wav
      audio/mp4
      audio/webm
      audio/ogg
      audio/flac
      audio/aac
      audio/x-wav
    ]
    validate_extension %w[mp3 wav m4a webm ogg flac aac]

    # Audio-specific validations
    validate :acceptable_duration
    validate :acceptable_quality
  end

  private

  def acceptable_duration
    return unless file

    duration = file[:metadata][&quot;audio_properties&quot;]&amp;.dig(&quot;duration&quot;)
    if duration
      errors &lt;&lt; &quot;Audio too long (#{duration}s)&quot; if duration &gt; 3600 # 1 hour max
      errors &lt;&lt; &quot;Audio too short (#{duration}s)&quot; if duration &lt; 1   # 1 second min
    end
  end
end
</code></pre>
<h3 id="processing-pipelines">Processing Pipelines</h3>
<p>Integrated processing workflows with background jobs:</p>
<pre><code class="language-ruby"># Processing pipeline integration
module Ragdoll
  module Core
    module FileProcessing
      def self.process_uploaded_file(content_model)
        case content_model.type
        when 'Ragdoll::Core::Models::TextContent'
          process_text_file(content_model)
        when 'Ragdoll::Core::Models::ImageContent'
          process_image_file(content_model)
        when 'Ragdoll::Core::Models::AudioContent'
          process_audio_file(content_model)
        end
      end

      private

      def self.process_text_file(text_content)
        # Extract text content from file
        if text_content.data.present?
          extracted_text = extract_text_from_file(text_content.data)
          text_content.update!(content: extracted_text)

          # Queue embedding generation
          Ragdoll::Core::Jobs::GenerateEmbeddings.perform_later(
            text_content.document_id
          )
        end
      end

      def self.process_image_file(image_content)
        # Generate image description using vision AI
        if image_content.data.present?
          description = generate_image_description(image_content.data)
          image_content.update!(content: description) # Store description in content field

          # Queue embedding generation for the description
          Ragdoll::Core::Jobs::GenerateEmbeddings.perform_later(
            image_content.document_id
          )
        end
      end

      def self.process_audio_file(audio_content)
        # Transcribe audio to text
        if audio_content.data.present?
          transcript = transcribe_audio(audio_content.data)
          audio_content.update!(content: transcript) # Store transcript in content field

          # Queue embedding generation for the transcript
          Ragdoll::Core::Jobs::GenerateEmbeddings.perform_later(
            audio_content.document_id
          )
        end
      end
    end
  end
end

# Automatic processing triggers
module Ragdoll
  module Core
    module Models
      class Content &lt; ActiveRecord::Base
        # Trigger processing after file attachment
        after_commit :process_file_if_attached, on: [:create, :update]

        private

        def process_file_if_attached
          if data_previously_changed? &amp;&amp; data.present?
            FileProcessing.process_uploaded_file(self)
          end
        end
      end
    end
  end
end
</code></pre>
<h2 id="supported-file-types">Supported File Types</h2>
<p>Ragdoll provides comprehensive support for multiple file formats across text, image, and audio content types.</p>
<h3 id="text-documents">Text Documents</h3>
<p>Extensive document format support with intelligent content extraction:</p>
<p><strong>Primary Formats:</strong></p>
<pre><code class="language-ruby">SUPPORTED_TEXT_FORMATS = {
  'application/pdf' =&gt; {
    extensions: ['.pdf'],
    max_size: 50.megabytes,
    extraction_method: :pdf_reader,
    features: [:text_extraction, :metadata_extraction, :page_analysis]
  },
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document' =&gt; {
    extensions: ['.docx'],
    max_size: 25.megabytes,
    extraction_method: :docx_parser,
    features: [:text_extraction, :formatting_preservation, :image_extraction]
  },
  'text/plain' =&gt; {
    extensions: ['.txt'],
    max_size: 5.megabytes,
    extraction_method: :direct_read,
    features: [:encoding_detection, :charset_conversion]
  },
  'text/html' =&gt; {
    extensions: ['.html', '.htm'],
    max_size: 10.megabytes,
    extraction_method: :html_parser,
    features: [:tag_stripping, :link_extraction, :metadata_extraction]
  },
  'text/markdown' =&gt; {
    extensions: ['.md', '.markdown'],
    max_size: 5.megabytes,
    extraction_method: :markdown_parser,
    features: [:structure_preservation, :link_extraction, :code_block_handling]
  },
  'application/json' =&gt; {
    extensions: ['.json'],
    max_size: 10.megabytes,
    extraction_method: :json_parser,
    features: [:structure_analysis, :key_value_extraction]
  }
}
</code></pre>
<p><strong>Extended Support:</strong>
- <strong>RTF Documents</strong> (<code>.rtf</code>): Rich Text Format with formatting preservation
- <strong>Legacy Word</strong> (<code>.doc</code>): Microsoft Word 97-2003 format
- <strong>CSV Files</strong> (<code>.csv</code>): Structured data with column analysis
- <strong>XML Files</strong> (<code>.xml</code>): Structured markup with schema detection
- <strong>YAML Files</strong> (<code>.yml</code>, <code>.yaml</code>): Configuration and data files</p>
<p><strong>Content Extraction Examples:</strong></p>
<pre><code class="language-ruby"># PDF text extraction with metadata
def extract_pdf_content(file_path)
  require 'pdf-reader'

  reader = PDF::Reader.new(file_path)
  content = {
    text: reader.pages.map(&amp;:text).join(&quot;\n\n&quot;),
    metadata: {
      page_count: reader.page_count,
      pdf_version: reader.pdf_version,
      info: reader.info,
      encrypted: reader.encrypted?
    }
  }

  content
end

# DOCX extraction with structure preservation
def extract_docx_content(file_path)
  require 'docx'

  doc = Docx::Document.open(file_path)
  {
    text: doc.paragraphs.map(&amp;:text).join(&quot;\n&quot;),
    metadata: {
      paragraph_count: doc.paragraphs.length,
      has_tables: doc.tables.any?,
      has_images: doc.images.any?,
      word_count: doc.paragraphs.map(&amp;:text).join(' ').split.length
    }
  }
end
</code></pre>
<h3 id="image-files">Image Files</h3>
<p>Comprehensive image format support with AI-powered content analysis:</p>
<p><strong>Supported Formats:</strong></p>
<pre><code class="language-ruby">SUPPORTED_IMAGE_FORMATS = {
  'image/jpeg' =&gt; {
    extensions: ['.jpg', '.jpeg'],
    max_size: 10.megabytes,
    features: [:exif_extraction, :quality_assessment, :color_analysis]
  },
  'image/png' =&gt; {
    extensions: ['.png'],
    max_size: 15.megabytes,
    features: [:transparency_detection, :compression_analysis, :metadata_extraction]
  },
  'image/gif' =&gt; {
    extensions: ['.gif'],
    max_size: 20.megabytes,
    features: [:animation_detection, :frame_extraction, :color_palette_analysis]
  },
  'image/webp' =&gt; {
    extensions: ['.webp'],
    max_size: 10.megabytes,
    features: [:modern_compression, :quality_optimization', :animation_support]
  },
  'image/svg+xml' =&gt; {
    extensions: ['.svg'],
    max_size: 2.megabytes,
    features: [:vector_analysis, :text_extraction, :element_parsing]
  },
  'image/tiff' =&gt; {
    extensions: ['.tiff', '.tif'],
    max_size: 50.megabytes,
    features: [:multi_page_support, :high_quality_preservation, :metadata_rich]
  },
  'image/bmp' =&gt; {
    extensions: ['.bmp'],
    max_size: 25.megabytes,
    features: [:uncompressed_quality, :color_depth_analysis]
  }
}
</code></pre>
<p><strong>AI-Powered Image Analysis:</strong></p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    class ImageAnalyzer
      def self.analyze_image(image_file)
        {
          description: generate_description(image_file),
          objects_detected: detect_objects(image_file),
          text_content: extract_text_ocr(image_file),
          visual_features: analyze_visual_features(image_file),
          metadata: extract_technical_metadata(image_file)
        }
      end

      private

      def self.generate_description(image_file)
        # Integration with vision AI services
        # OpenAI GPT-4 Vision, Google Vision AI, etc.
        &quot;A detailed description of the image content&quot;
      end

      def self.detect_objects(image_file)
        # Object detection using AI models
        [
          { object: 'person', confidence: 0.95, bbox: [10, 20, 100, 200] },
          { object: 'building', confidence: 0.87, bbox: [150, 30, 300, 250] }
        ]
      end

      def self.extract_text_ocr(image_file)
        # OCR text extraction for images with text
        &quot;Text found in image through OCR&quot;
      end
    end
  end
end
</code></pre>
<h3 id="audio-files">Audio Files</h3>
<p>Comprehensive audio format support with transcription and analysis:</p>
<p><strong>Supported Formats:</strong></p>
<pre><code class="language-ruby">SUPPORTED_AUDIO_FORMATS = {
  'audio/mpeg' =&gt; {
    extensions: ['.mp3'],
    max_size: 100.megabytes,
    max_duration: 3600, # 1 hour
    features: [:id3_metadata, :variable_bitrate, :wide_compatibility]
  },
  'audio/wav' =&gt; {
    extensions: ['.wav'],
    max_size: 500.megabytes,
    max_duration: 3600,
    features: [:uncompressed_quality, :professional_standard, :metadata_support]
  },
  'audio/mp4' =&gt; {
    extensions: ['.m4a', '.mp4'],
    max_size: 150.megabytes,
    max_duration: 3600,
    features: [:aac_compression, :chapter_support, :metadata_rich]
  },
  'audio/webm' =&gt; {
    extensions: ['.webm'],
    max_size: 100.megabytes,
    max_duration: 3600,
    features: [:web_optimized, :open_standard, :good_compression]
  },
  'audio/ogg' =&gt; {
    extensions: ['.ogg'],
    max_size: 100.megabytes,
    max_duration: 3600,
    features: [:open_source, :good_quality, :vorbis_codec]
  },
  'audio/flac' =&gt; {
    extensions: ['.flac'],
    max_size: 1000.megabytes,
    max_duration: 3600,
    features: [:lossless_compression, :high_quality, :metadata_support]
  },
  'audio/aac' =&gt; {
    extensions: ['.aac'],
    max_size: 100.megabytes,
    max_duration: 3600,
    features: [:efficient_compression, :good_quality, :mobile_optimized]
  }
}
</code></pre>
<p><strong>Audio Processing and Transcription:</strong></p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    class AudioProcessor
      def self.process_audio(audio_file)
        {
          transcript: transcribe_audio(audio_file),
          metadata: extract_audio_metadata(audio_file),
          analysis: analyze_audio_content(audio_file),
          quality_metrics: assess_audio_quality(audio_file)
        }
      end

      private

      def self.transcribe_audio(audio_file)
        # Integration with speech-to-text services
        # OpenAI Whisper, Google Speech-to-Text, AWS Transcribe
        {
          text: &quot;Transcribed text from audio&quot;,
          confidence: 0.95,
          language: 'en',
          timestamps: [
            { start: 0.0, end: 5.2, text: &quot;Hello, this is the beginning&quot; },
            { start: 5.2, end: 10.1, text: &quot;of the audio transcription&quot; }
          ]
        }
      end

      def self.extract_audio_metadata(audio_file)
        # Extract technical and ID3 metadata
        {
          duration: 180.5, # seconds
          sample_rate: 44100,
          channels: 2,
          bitrate: 320, # kbps
          format: 'MP3',
          id3_tags: {
            title: 'Audio Title',
            artist: 'Artist Name',
            album: 'Album Name',
            year: 2024
          }
        }
      end

      def self.analyze_audio_content(audio_file)
        # Audio content analysis (speech patterns, music detection, etc.)
        {
          content_type: 'speech', # speech, music, mixed, silence
          speech_segments: 15,
          music_segments: 0,
          silence_percentage: 5.2,
          dominant_language: 'english',
          speaker_count: 2,
          audio_quality: 'high'
        }
      end
    end
  end
end
</code></pre>
<h2 id="file-validation">File Validation</h2>
<p>Comprehensive file validation ensures security, quality, and system stability through multiple validation layers.</p>
<h3 id="multi-layer-validation-system">Multi-Layer Validation System</h3>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module FileValidation
      class ValidationEngine
        VALIDATION_LAYERS = [
          :basic_file_checks,
          :mime_type_validation,
          :file_size_validation,
          :security_scanning,
          :content_validation,
          :malware_detection
        ]

        def self.validate_file(file, content_type)
          results = {
            valid: true,
            errors: [],
            warnings: [],
            metadata: {}
          }

          VALIDATION_LAYERS.each do |layer|
            layer_result = send(layer, file, content_type)

            results[:errors].concat(layer_result[:errors])
            results[:warnings].concat(layer_result[:warnings])
            results[:metadata].merge!(layer_result[:metadata])

            # Stop validation if critical errors found
            if layer_result[:errors].any? { |e| e[:severity] == :critical }
              results[:valid] = false
              break
            end
          end

          results[:valid] = results[:errors].empty?
          results
        end

        private

        def self.basic_file_checks(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          # File existence and readability
          unless file.respond_to?(:read)
            errors &lt;&lt; { message: 'File is not readable', severity: :critical }
            return { errors: errors, warnings: warnings, metadata: metadata }
          end

          # File size basic check
          if file.respond_to?(:size) &amp;&amp; file.size == 0
            errors &lt;&lt; { message: 'File is empty', severity: :critical }
          end

          # Extract basic metadata
          metadata[:original_filename] = file.original_filename if file.respond_to?(:original_filename)
          metadata[:content_type] = file.content_type if file.respond_to?(:content_type)
          metadata[:file_size] = file.size if file.respond_to?(:size)

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        def self.mime_type_validation(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          # Determine actual MIME type
          actual_mime_type = Marcel::MimeType.for(file)
          declared_mime_type = file.content_type if file.respond_to?(:content_type)

          metadata[:actual_mime_type] = actual_mime_type
          metadata[:declared_mime_type] = declared_mime_type

          # Get allowed MIME types for content type
          allowed_types = get_allowed_mime_types(content_type)

          unless allowed_types.include?(actual_mime_type)
            errors &lt;&lt; {
              message: &quot;Unsupported file type: #{actual_mime_type}&quot;,
              severity: :critical,
              allowed_types: allowed_types
            }
          end

          # Check for MIME type spoofing
          if declared_mime_type &amp;&amp; declared_mime_type != actual_mime_type
            warnings &lt;&lt; {
              message: &quot;MIME type mismatch: declared #{declared_mime_type}, actual #{actual_mime_type}&quot;,
              severity: :medium
            }
          end

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        def self.file_size_validation(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          file_size = file.size if file.respond_to?(:size)
          return { errors: errors, warnings: warnings, metadata: metadata } unless file_size

          size_limits = get_size_limits(content_type)

          if file_size &gt; size_limits[:max_size]
            errors &lt;&lt; {
              message: &quot;File too large: #{file_size} bytes (max: #{size_limits[:max_size]})&quot;,
              severity: :critical
            }
          end

          if file_size &lt; size_limits[:min_size]
            warnings &lt;&lt; {
              message: &quot;File very small: #{file_size} bytes (min recommended: #{size_limits[:min_size]})&quot;,
              severity: :low
            }
          end

          metadata[:size_category] = categorize_file_size(file_size)

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        def self.security_scanning(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          # File signature validation
          file_signature = read_file_signature(file)
          metadata[:file_signature] = file_signature

          if suspicious_file_signature?(file_signature)
            errors &lt;&lt; {
              message: &quot;Suspicious file signature detected&quot;,
              severity: :critical
            }
          end

          # Embedded content scanning
          if content_type == 'document'
            embedded_content = scan_for_embedded_content(file)

            if embedded_content[:has_macros]
              warnings &lt;&lt; {
                message: &quot;Document contains macros&quot;,
                severity: :medium
              }
            end

            if embedded_content[:has_external_links]
              warnings &lt;&lt; {
                message: &quot;Document contains external links&quot;,
                severity: :low
              }
            end

            metadata[:embedded_content] = embedded_content
          end

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        def self.content_validation(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          case content_type
          when 'document'
            validate_document_content(file, errors, warnings, metadata)
          when 'image'
            validate_image_content(file, errors, warnings, metadata)
          when 'audio'
            validate_audio_content(file, errors, warnings, metadata)
          end

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        def self.malware_detection(file, content_type)
          errors = []
          warnings = []
          metadata = {}

          # Integration with antivirus services
          if ENV['CLAMAV_ENABLED'] == 'true'
            scan_result = scan_with_clamav(file)

            if scan_result[:infected]
              errors &lt;&lt; {
                message: &quot;Malware detected: #{scan_result[:virus_name]}&quot;,
                severity: :critical
              }
            end

            metadata[:malware_scan] = scan_result
          end

          # Behavioral analysis for suspicious files
          behavioral_analysis = analyze_file_behavior(file)
          metadata[:behavioral_analysis] = behavioral_analysis

          if behavioral_analysis[:suspicious_score] &gt; 0.7
            warnings &lt;&lt; {
              message: &quot;File shows suspicious characteristics&quot;,
              severity: :medium,
              details: behavioral_analysis
            }
          end

          { errors: errors, warnings: warnings, metadata: metadata }
        end

        # Helper methods
        def self.get_allowed_mime_types(content_type)
          case content_type
          when 'document'
            %w[
              application/pdf
              application/vnd.openxmlformats-officedocument.wordprocessingml.document
              text/plain
              text/html
              text/markdown
              application/json
            ]
          when 'image'
            %w[
              image/jpeg
              image/png
              image/gif
              image/webp
              image/bmp
              image/tiff
              image/svg+xml
            ]
          when 'audio'
            %w[
              audio/mpeg
              audio/wav
              audio/mp4
              audio/webm
              audio/ogg
              audio/flac
              audio/aac
            ]
          else
            []
          end
        end

        def self.get_size_limits(content_type)
          case content_type
          when 'document'
            { min_size: 10, max_size: 50.megabytes }
          when 'image'
            { min_size: 100, max_size: 10.megabytes }
          when 'audio'
            { min_size: 1000, max_size: 100.megabytes }
          else
            { min_size: 1, max_size: 10.megabytes }
          end
        end
      end
    end
  end
end
</code></pre>
<h3 id="specialized-validation-rules">Specialized Validation Rules</h3>
<p><strong>Document-Specific Validation:</strong></p>
<pre><code class="language-ruby">def validate_document_content(file, errors, warnings, metadata)
  begin
    case Marcel::MimeType.for(file)
    when 'application/pdf'
      pdf_validation = validate_pdf_document(file)
      errors.concat(pdf_validation[:errors])
      warnings.concat(pdf_validation[:warnings])
      metadata.merge!(pdf_validation[:metadata])

    when 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
      docx_validation = validate_docx_document(file)
      errors.concat(docx_validation[:errors])
      warnings.concat(docx_validation[:warnings])
      metadata.merge!(docx_validation[:metadata])
    end
  rescue =&gt; e
    errors &lt;&lt; {
      message: &quot;Document validation failed: #{e.message}&quot;,
      severity: :high
    }
  end
end

def validate_pdf_document(file)
  errors = []
  warnings = []
  metadata = {}

  begin
    reader = PDF::Reader.new(file)

    # Check if PDF is encrypted
    if reader.encrypted?
      errors &lt;&lt; {
        message: &quot;PDF is password protected&quot;,
        severity: :critical
      }
    end

    # Check page count
    page_count = reader.page_count
    metadata[:page_count] = page_count

    if page_count &gt; 1000
      warnings &lt;&lt; {
        message: &quot;PDF has many pages (#{page_count}), processing may be slow&quot;,
        severity: :low
      }
    end

    # Check PDF version
    pdf_version = reader.pdf_version
    metadata[:pdf_version] = pdf_version

    if pdf_version &gt; 1.7
      warnings &lt;&lt; {
        message: &quot;PDF version #{pdf_version} may have compatibility issues&quot;,
        severity: :low
      }
    end

    # Check for text content
    has_text = reader.pages.any? { |page| page.text.strip.length &gt; 0 }
    metadata[:has_extractable_text] = has_text

    unless has_text
      warnings &lt;&lt; {
        message: &quot;PDF appears to contain no extractable text (may be image-only)&quot;,
        severity: :medium
      }
    end

  rescue PDF::Reader::MalformedPDFError =&gt; e
    errors &lt;&lt; {
      message: &quot;PDF file is malformed: #{e.message}&quot;,
      severity: :critical
    }
  rescue =&gt; e
    errors &lt;&lt; {
      message: &quot;PDF validation error: #{e.message}&quot;,
      severity: :high
    }
  end

  { errors: errors, warnings: warnings, metadata: metadata }
end
</code></pre>
<p><strong>Image-Specific Validation:</strong></p>
<pre><code class="language-ruby">def validate_image_content(file, errors, warnings, metadata)
  begin
    # Use ImageMagick or similar for image analysis
    image_info = extract_image_info(file)
    metadata.merge!(image_info)

    # Check image dimensions
    if image_info[:width] &amp;&amp; image_info[:height]
      total_pixels = image_info[:width] * image_info[:height]

      if total_pixels &gt; 50_000_000 # 50 megapixels
        warnings &lt;&lt; {
          message: &quot;Very high resolution image (#{image_info[:width]}x#{image_info[:height]})&quot;,
          severity: :medium
        }
      end

      if image_info[:width] &lt; 50 || image_info[:height] &lt; 50
        warnings &lt;&lt; {
          message: &quot;Very small image (#{image_info[:width]}x#{image_info[:height]})&quot;,
          severity: :low
        }
      end
    end

    # Check color depth
    if image_info[:bit_depth] &amp;&amp; image_info[:bit_depth] &gt; 16
      warnings &lt;&lt; {
        message: &quot;High bit depth (#{image_info[:bit_depth]}) may not be preserved&quot;,
        severity: :low
      }
    end

    # Check for transparency
    if image_info[:has_alpha]
      metadata[:supports_transparency] = true
    end

  rescue =&gt; e
    errors &lt;&lt; {
      message: &quot;Image validation error: #{e.message}&quot;,
      severity: :high
    }
  end
end
</code></pre>
<h3 id="security-integration">Security Integration</h3>
<p><strong>ClamAV Integration:</strong></p>
<pre><code class="language-ruby">def scan_with_clamav(file)
  return { scanned: false, reason: 'ClamAV not available' } unless clamav_available?

  begin
    # Create temporary file for scanning
    temp_file = Tempfile.new('ragdoll_scan')
    temp_file.binmode
    temp_file.write(file.read)
    temp_file.close
    file.rewind

    # Run ClamAV scan
    result = `clamscan --no-summary --infected #{temp_file.path}`
    exit_code = $?.exitstatus

    scan_result = {
      scanned: true,
      infected: exit_code == 1,
      virus_name: nil,
      scan_output: result.strip
    }

    if scan_result[:infected]
      # Extract virus name from output
      if match = result.match(/: (.+) FOUND$/)
        scan_result[:virus_name] = match[1]
      end
    end

    scan_result

  rescue =&gt; e
    { scanned: false, error: e.message }
  ensure
    temp_file&amp;.unlink
  end
end

def clamav_available?
  `which clamscan` &amp;&amp; $?.success?
rescue
  false
end
</code></pre>
<p><strong>Behavioral Analysis:</strong></p>
<pre><code class="language-ruby">def analyze_file_behavior(file)
  suspicious_score = 0.0
  indicators = []

  # Check file extension vs content mismatch
  if extension_content_mismatch?(file)
    suspicious_score += 0.3
    indicators &lt;&lt; 'extension_mismatch'
  end

  # Check for unusual file patterns
  if unusual_file_pattern?(file)
    suspicious_score += 0.2
    indicators &lt;&lt; 'unusual_pattern'
  end

  # Check for embedded executables
  if contains_embedded_executable?(file)
    suspicious_score += 0.5
    indicators &lt;&lt; 'embedded_executable'
  end

  {
    suspicious_score: suspicious_score,
    indicators: indicators,
    risk_level: categorize_risk_level(suspicious_score)
  }
end

def categorize_risk_level(score)
  case score
  when 0...0.3 then 'low'
  when 0.3...0.6 then 'medium'
  when 0.6...0.8 then 'high'
  else 'critical'
  end
end
</code></pre>
<h2 id="storage-configuration">Storage Configuration</h2>
<p>Ragdoll supports multiple storage backends through Shrine's flexible architecture, enabling deployment across various infrastructure scenarios.</p>
<h3 id="local-filesystem-storage">Local Filesystem Storage</h3>
<p>Ideal for development, testing, and small-scale deployments:</p>
<pre><code class="language-ruby"># Basic filesystem configuration
Shrine.storages = {
  cache: Shrine::Storage::FileSystem.new(&quot;tmp/uploads&quot;, prefix: &quot;cache&quot;),
  store: Shrine::Storage::FileSystem.new(&quot;public/uploads&quot;)
}

# Advanced filesystem configuration
Shrine.storages = {
  cache: Shrine::Storage::FileSystem.new(
    &quot;tmp/ragdoll_cache&quot;,
    prefix: &quot;cache&quot;,
    permissions: 0644,
    directory_permissions: 0755,
    clean: true  # Clean up empty directories
  ),
  store: Shrine::Storage::FileSystem.new(
    &quot;storage/ragdoll_files&quot;,
    prefix: &quot;#{Rails.env}/files&quot;,  # Environment-specific paths
    permissions: 0644,
    directory_permissions: 0755,
    host: &quot;https://example.com&quot;   # For generating URLs
  )
}

# Custom directory structure
class CustomFileSystem &lt; Shrine::Storage::FileSystem
  def generate_location(io, **options)
    # Organize files by date and content type
    date_path = Date.current.strftime(&quot;%Y/%m/%d&quot;)
    content_type = options[:metadata]&amp;.dig(&quot;mime_type&quot;) || &quot;unknown&quot;
    type_dir = content_type.split(&quot;/&quot;).first # e.g., &quot;image&quot;, &quot;audio&quot;, &quot;application&quot;

    &quot;#{type_dir}/#{date_path}/#{super}&quot;
  end
end

Shrine.storages = {
  cache: CustomFileSystem.new(&quot;tmp/uploads&quot;),
  store: CustomFileSystem.new(&quot;storage/files&quot;)
}
</code></pre>
<p><strong>Filesystem Storage Benefits:</strong>
- Simple setup and configuration
- No external dependencies
- Full control over file organization
- Easy backup and migration
- No API rate limits or costs</p>
<p><strong>Considerations:</strong>
- Limited scalability
- Single point of failure
- No built-in CDN capabilities
- Requires local disk space management</p>
<h3 id="amazon-s3-integration">Amazon S3 Integration</h3>
<p>Recommended for production deployments with scalability requirements:</p>
<pre><code class="language-ruby"># Gemfile
gem &quot;aws-sdk-s3&quot;, &quot;~&gt; 1.14&quot;

# S3 configuration
require &quot;shrine/storage/s3&quot;

# Basic S3 setup
Shrine.storages = {
  cache: Shrine::Storage::S3.new(
    bucket: ENV['S3_CACHE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']
  ),
  store: Shrine::Storage::S3.new(
    bucket: ENV['S3_STORAGE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']
  )
}

# Advanced S3 configuration
Shrine.storages = {
  cache: Shrine::Storage::S3.new(
    bucket: ENV['S3_CACHE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
    prefix: &quot;ragdoll/cache/#{Rails.env}&quot;,
    public: false,
    upload: {
      server_side_encryption: &quot;AES256&quot;,
      metadata_directive: &quot;REPLACE&quot;
    },
    signer: { expires_in: 1.hour } # Presigned URL expiration
  ),
  store: Shrine::Storage::S3.new(
    bucket: ENV['S3_STORAGE_BUCKET'],
    region: ENV['AWS_REGION'],
    access_key_id: ENV['AWS_ACCESS_KEY_ID'],
    secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
    prefix: &quot;ragdoll/files/#{Rails.env}&quot;,
    public: false,  # Private files for security
    upload: {
      server_side_encryption: &quot;AES256&quot;,
      storage_class: &quot;STANDARD_IA&quot;, # Infrequent Access for cost optimization
      metadata_directive: &quot;REPLACE&quot;
    },
    signer: { expires_in: 24.hours }
  )
}

# S3-specific plugins
Shrine.plugin :presign_endpoint, presign_options: -&gt; (request) {
  {
    content_length_range: 0..50.megabytes,
    content_type: request.params[&quot;content_type&quot;],
    expires_in: 1.hour
  }
}

Shrine.plugin :upload_endpoint, max_size: 50.megabytes
</code></pre>
<p><strong>S3 Lifecycle Management:</strong></p>
<pre><code class="language-ruby"># S3 lifecycle configuration for cost optimization
class S3LifecycleManager
  def self.configure_lifecycle_rules
    s3_client = Aws::S3::Client.new(
      region: ENV['AWS_REGION'],
      access_key_id: ENV['AWS_ACCESS_KEY_ID'],
      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']
    )

    # Configure lifecycle rules
    lifecycle_configuration = {
      rules: [
        {
          id: 'ragdoll-cache-cleanup',
          status: 'Enabled',
          filter: { prefix: 'ragdoll/cache/' },
          expiration: { days: 1 }, # Delete cache files after 1 day
        },
        {
          id: 'ragdoll-files-archive',
          status: 'Enabled',
          filter: { prefix: 'ragdoll/files/' },
          transitions: [
            {
              days: 30,
              storage_class: 'STANDARD_IA' # Move to Infrequent Access after 30 days
            },
            {
              days: 90,
              storage_class: 'GLACIER' # Archive to Glacier after 90 days
            }
          ]
        }
      ]
    }

    s3_client.put_bucket_lifecycle_configuration(
      bucket: ENV['S3_STORAGE_BUCKET'],
      lifecycle_configuration: lifecycle_configuration
    )
  end
end
</code></pre>
<h3 id="google-cloud-storage">Google Cloud Storage</h3>
<p>Excellent alternative to S3 with similar features:</p>
<pre><code class="language-ruby"># Gemfile
gem &quot;google-cloud-storage&quot;, &quot;~&gt; 1.11&quot;

# GCS configuration
require &quot;shrine/storage/google_cloud_storage&quot;

Shrine.storages = {
  cache: Shrine::Storage::GoogleCloudStorage.new(
    bucket: ENV['GCS_CACHE_BUCKET'],
    project: ENV['GOOGLE_CLOUD_PROJECT'],
    credentials: ENV['GOOGLE_CLOUD_KEYFILE'],
    prefix: &quot;ragdoll/cache/#{Rails.env}&quot;,
    object_options: {
      cache_control: &quot;public, max-age=3600&quot;,
      metadata: {
        environment: Rails.env,
        application: &quot;ragdoll&quot;
      }
    }
  ),
  store: Shrine::Storage::GoogleCloudStorage.new(
    bucket: ENV['GCS_STORAGE_BUCKET'],
    project: ENV['GOOGLE_CLOUD_PROJECT'],
    credentials: ENV['GOOGLE_CLOUD_KEYFILE'],
    prefix: &quot;ragdoll/files/#{Rails.env}&quot;,
    default_acl: &quot;private&quot;, # Private files for security
    object_options: {
      storage_class: &quot;NEARLINE&quot;, # Cost-effective for infrequent access
      metadata: {
        environment: Rails.env,
        application: &quot;ragdoll&quot;,
        retention_policy: &quot;365days&quot;
      }
    }
  )
}

# GCS-specific features
class GCSManager
  def self.setup_bucket_policies
    storage = Google::Cloud::Storage.new(
      project_id: ENV['GOOGLE_CLOUD_PROJECT'],
      credentials: ENV['GOOGLE_CLOUD_KEYFILE']
    )

    bucket = storage.bucket(ENV['GCS_STORAGE_BUCKET'])

    # Set up lifecycle management
    bucket.lifecycle do |l|
      l.add_rule {
        l.action :delete
        l.condition age: 365 # Delete files older than 1 year
        l.condition matches_prefix: &quot;ragdoll/cache/&quot;
      }

      l.add_rule {
        l.action :set_storage_class, storage_class: &quot;COLDLINE&quot;
        l.condition age: 90
        l.condition matches_prefix: &quot;ragdoll/files/&quot;
      }
    end

    # Enable uniform bucket-level access
    bucket.uniform_bucket_level_access = true
  end
end
</code></pre>
<h3 id="azure-blob-storage">Azure Blob Storage</h3>
<p>Integration with Microsoft Azure ecosystem:</p>
<pre><code class="language-ruby"># Gemfile
gem &quot;azure-storage-blob&quot;, &quot;~&gt; 2.0&quot;

# Custom Azure storage implementation
class AzureBlobStorage
  def initialize(container:, account_name:, account_key:, **options)
    @container = container
    @client = Azure::Storage::Blob::BlobService.create(
      storage_account_name: account_name,
      storage_access_key: account_key
    )
    @prefix = options[:prefix]
    @public = options[:public] != false
  end

  def upload(io, id, shrine_metadata: {}, **options)
    content_type = shrine_metadata[&quot;mime_type&quot;]

    @client.create_block_blob(
      @container,
      path(id),
      io.read,
      content_type: content_type,
      metadata: {
        &quot;shrine_metadata&quot; =&gt; JSON.generate(shrine_metadata),
        &quot;ragdoll_version&quot; =&gt; Ragdoll::Core::VERSION
      }
    )
  end

  def download(id)
    blob, content = @client.get_blob(@container, path(id))
    StringIO.new(content)
  end

  def exists?(id)
    @client.get_blob_properties(@container, path(id))
    true
  rescue Azure::Core::Http::HTTPError =&gt; e
    raise unless e.status_code == 404
    false
  end

  def delete(id)
    @client.delete_blob(@container, path(id))
  end

  def url(id, **options)
    if @public
      @client.generate_uri(path(id), @container)
    else
      # Generate SAS token for private access
      @client.generate_uri(path(id), @container, {
        permissions: &quot;r&quot;,
        expiry: (Time.now + 1.hour).utc.iso8601
      })
    end
  end

  private

  def path(id)
    [@prefix, id].compact.join(&quot;/&quot;)
  end
end

# Azure configuration
Shrine.storages = {
  cache: AzureBlobStorage.new(
    container: ENV['AZURE_CACHE_CONTAINER'],
    account_name: ENV['AZURE_STORAGE_ACCOUNT'],
    account_key: ENV['AZURE_STORAGE_KEY'],
    prefix: &quot;ragdoll/cache/#{Rails.env}&quot;,
    public: false
  ),
  store: AzureBlobStorage.new(
    container: ENV['AZURE_STORAGE_CONTAINER'],
    account_name: ENV['AZURE_STORAGE_ACCOUNT'],
    account_key: ENV['AZURE_STORAGE_KEY'],
    prefix: &quot;ragdoll/files/#{Rails.env}&quot;,
    public: false
  )
}
</code></pre>
<h3 id="cdn-integration">CDN Integration</h3>
<p>Optimize file delivery with Content Delivery Networks:</p>
<p><strong>CloudFront (AWS) Integration:</strong></p>
<pre><code class="language-ruby"># CloudFront configuration for S3
class CloudFrontIntegration
  def self.configure_distribution
    cloudfront = Aws::CloudFront::Client.new(
      region: 'us-east-1', # CloudFront is global but API is in us-east-1
      access_key_id: ENV['AWS_ACCESS_KEY_ID'],
      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY']
    )

    distribution_config = {
      caller_reference: &quot;ragdoll-#{Time.current.to_i}&quot;,
      aliases: {
        quantity: 1,
        items: [ENV['CDN_DOMAIN']] # e.g., cdn.example.com
      },
      default_root_object: &quot;index.html&quot;,
      origins: {
        quantity: 1,
        items: [{
          id: &quot;ragdoll-s3-origin&quot;,
          domain_name: &quot;#{ENV['S3_STORAGE_BUCKET']}.s3.#{ENV['AWS_REGION']}.amazonaws.com&quot;,
          s3_origin_config: {
            origin_access_identity: &quot;origin-access-identity/cloudfront/#{ENV['OAI_ID']}&quot;
          }
        }]
      },
      default_cache_behavior: {
        target_origin_id: &quot;ragdoll-s3-origin&quot;,
        viewer_protocol_policy: &quot;redirect-to-https&quot;,
        trusted_signers: {
          enabled: false,
          quantity: 0
        },
        forwarded_values: {
          query_string: false,
          cookies: {
            forward: &quot;none&quot;
          }
        },
        min_ttl: 0,
        default_ttl: 86400, # 24 hours
        max_ttl: 31536000   # 1 year
      },
      comment: &quot;Ragdoll file distribution&quot;,
      enabled: true,
      price_class: &quot;PriceClass_100&quot; # Use only North America and Europe edge locations
    }

    response = cloudfront.create_distribution(distribution_config: distribution_config)
    response.distribution.domain_name
  end
end

# URL generation with CDN
class CDNFileUploader &lt; Shrine
  def self.cdn_url(file)
    if Rails.env.production? &amp;&amp; ENV['CDN_DOMAIN']
      file.url.gsub(
        &quot;#{ENV['S3_STORAGE_BUCKET']}.s3.#{ENV['AWS_REGION']}.amazonaws.com&quot;,
        ENV['CDN_DOMAIN']
      )
    else
      file.url
    end
  end
end
</code></pre>
<p><strong>Multi-CDN Strategy:</strong></p>
<pre><code class="language-ruby">class MultiCDNManager
  CDN_PROVIDERS = {
    cloudflare: {
      domain: ENV['CLOUDFLARE_CDN_DOMAIN'],
      priority: 1
    },
    cloudfront: {
      domain: ENV['CLOUDFRONT_CDN_DOMAIN'],
      priority: 2
    },
    fastly: {
      domain: ENV['FASTLY_CDN_DOMAIN'],
      priority: 3
    }
  }

  def self.get_optimized_url(file, user_location: nil)
    # Select best CDN based on user location and CDN health
    best_cdn = select_optimal_cdn(user_location)

    if best_cdn &amp;&amp; best_cdn[:domain]
      # Replace origin domain with CDN domain
      original_url = file.url
      cdn_url = original_url.gsub(
        /https:\/\/[^.]+\.s3\.[^.]+\.amazonaws\.com/,
        &quot;https://#{best_cdn[:domain]}&quot;
      )

      # Add cache busting and optimization parameters
      add_optimization_params(cdn_url, file)
    else
      file.url # Fallback to original URL
    end
  end

  private

  def self.select_optimal_cdn(user_location)
    # Health check CDNs and select best performing
    available_cdns = CDN_PROVIDERS.select { |name, config| 
      cdn_healthy?(config[:domain]) 
    }

    # Select based on priority and user location
    available_cdns.min_by { |name, config| config[:priority] }&amp;.last
  end

  def self.cdn_healthy?(domain)
    # Simple health check
    begin
      response = Net::HTTP.get_response(URI(&quot;https://#{domain}/health&quot;))
      response.code == '200'
    rescue
      false
    end
  end

  def self.add_optimization_params(url, file)
    # Add image optimization parameters for supported CDNs
    if file.metadata['mime_type']&amp;.start_with?('image/')
      &quot;#{url}?auto=compress,format&amp;w=1200&amp;q=85&quot;
    else
      url
    end
  end
end
</code></pre>
<h3 id="hybrid-storage-strategy">Hybrid Storage Strategy</h3>
<p>Combine multiple storage backends for optimal performance and cost:</p>
<pre><code class="language-ruby">class HybridStorageManager
  def self.configure_hybrid_storage
    # Hot storage: Frequently accessed files (S3 Standard)
    hot_storage = Shrine::Storage::S3.new(
      bucket: ENV['S3_HOT_BUCKET'],
      region: ENV['AWS_REGION'],
      access_key_id: ENV['AWS_ACCESS_KEY_ID'],
      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
      prefix: &quot;ragdoll/hot&quot;,
      upload: { storage_class: &quot;STANDARD&quot; }
    )

    # Warm storage: Occasionally accessed files (S3 Standard-IA)
    warm_storage = Shrine::Storage::S3.new(
      bucket: ENV['S3_WARM_BUCKET'],
      region: ENV['AWS_REGION'],
      access_key_id: ENV['AWS_ACCESS_KEY_ID'],
      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
      prefix: &quot;ragdoll/warm&quot;,
      upload: { storage_class: &quot;STANDARD_IA&quot; }
    )

    # Cold storage: Rarely accessed files (S3 Glacier)
    cold_storage = Shrine::Storage::S3.new(
      bucket: ENV['S3_COLD_BUCKET'],
      region: ENV['AWS_REGION'],
      access_key_id: ENV['AWS_ACCESS_KEY_ID'],
      secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'],
      prefix: &quot;ragdoll/cold&quot;,
      upload: { storage_class: &quot;GLACIER&quot; }
    )

    {
      cache: Shrine::Storage::FileSystem.new(&quot;tmp/uploads&quot;),
      hot: hot_storage,
      warm: warm_storage,
      cold: cold_storage
    }
  end

  def self.migrate_files_by_usage
    # Move files between storage tiers based on access patterns

    # Move frequently accessed files to hot storage
    frequently_accessed = Ragdoll::Core::Models::Embedding
      .where('usage_count &gt; ? AND returned_at &gt; ?', 10, 30.days.ago)
      .includes(:embeddable)

    frequently_accessed.each do |embedding|
      content = embedding.embeddable
      if content.data.storage_key != :hot
        migrate_file_to_storage(content, :hot)
      end
    end

    # Move rarely accessed files to cold storage
    rarely_accessed = Ragdoll::Core::Models::Embedding
      .where('usage_count &lt; ? AND (returned_at IS NULL OR returned_at &lt; ?)', 2, 90.days.ago)
      .includes(:embeddable)

    rarely_accessed.each do |embedding|
      content = embedding.embeddable
      if content.data.storage_key == :hot
        migrate_file_to_storage(content, :cold)
      end
    end
  end

  private

  def self.migrate_file_to_storage(content, target_storage)
    # Download from current storage
    current_file = content.data

    # Upload to target storage
    new_file = content.data_attacher.upload(
      current_file.download,
      storage: target_storage
    )

    # Update content record
    content.update!(data: new_file)

    # Delete from old storage
    current_file.delete
  end
end
</code></pre>
<h2 id="file-processing-pipeline">File Processing Pipeline</h2>
<p>Ragdoll implements a comprehensive file processing pipeline that ensures secure, efficient handling of uploaded files through multiple stages.</p>
<h3 id="processing-workflow-overview">Processing Workflow Overview</h3>
<pre><code class="language-mermaid">flowchart TD
    A[File Upload] --&gt; B[Temporary Storage]
    B --&gt; C[File Validation]
    C --&gt; D{Validation Passed?}
    D --&gt;|No| E[Reject Upload]
    D --&gt;|Yes| F[Metadata Extraction]
    F --&gt; G[Security Scanning]
    G --&gt; H{Security Check?}
    H --&gt;|Failed| I[Quarantine File]
    H --&gt;|Passed| J[Content Processing]
    J --&gt; K[Permanent Storage]
    K --&gt; L[Database Record Creation]
    L --&gt; M[Background Job Queuing]
    M --&gt; N[Embedding Generation]
    N --&gt; O[Content Analysis]
    O --&gt; P[Processing Complete]
</code></pre>
<h3 id="stage-1-file-upload-and-temporary-storage">Stage 1: File Upload and Temporary Storage</h3>
<p>Initial file reception with immediate temporary storage:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    class FileUploadHandler
      def self.handle_upload(uploaded_file, document_id, content_type)
        upload_result = {
          success: false,
          file_id: nil,
          metadata: {},
          errors: [],
          processing_stages: []
        }

        begin
          # Stage 1: Temporary storage
          upload_result[:processing_stages] &lt;&lt; {
            stage: 'temporary_storage',
            started_at: Time.current,
            status: 'started'
          }

          # Create temporary file with unique identifier
          temp_file_id = generate_temp_file_id
          temp_file = store_temporarily(uploaded_file, temp_file_id)

          upload_result[:file_id] = temp_file_id
          upload_result[:metadata][:temp_location] = temp_file.id
          upload_result[:metadata][:original_filename] = uploaded_file.original_filename
          upload_result[:metadata][:content_type] = uploaded_file.content_type
          upload_result[:metadata][:file_size] = uploaded_file.size

          upload_result[:processing_stages].last[:status] = 'completed'
          upload_result[:processing_stages].last[:completed_at] = Time.current

          # Proceed to validation
          validation_result = FileValidation::ValidationEngine.validate_file(
            temp_file, content_type
          )

          if validation_result[:valid]
            upload_result.merge!(process_validated_file(
              temp_file, document_id, content_type, upload_result
            ))
          else
            upload_result[:errors] = validation_result[:errors]
            cleanup_temp_file(temp_file)
          end

        rescue =&gt; e
          upload_result[:errors] &lt;&lt; {
            stage: 'upload_handling',
            message: e.message,
            backtrace: e.backtrace&amp;.first(5)
          }

          cleanup_temp_file(temp_file) if temp_file
        end

        upload_result
      end

      private

      def self.generate_temp_file_id
        &quot;temp_#{SecureRandom.uuid}_#{Time.current.to_i}&quot;
      end

      def self.store_temporarily(uploaded_file, temp_id)
        # Use cache storage for temporary files
        cache_storage = Shrine.storages[:cache]

        # Store with metadata
        cache_storage.upload(
          uploaded_file,
          temp_id,
          shrine_metadata: {
            'filename' =&gt; uploaded_file.original_filename,
            'mime_type' =&gt; uploaded_file.content_type,
            'size' =&gt; uploaded_file.size
          }
        )

        # Return Shrine uploaded file object
        Shrine::UploadedFile.new(
          id: temp_id,
          storage: :cache,
          metadata: {
            'filename' =&gt; uploaded_file.original_filename,
            'mime_type' =&gt; uploaded_file.content_type,
            'size' =&gt; uploaded_file.size
          }
        )
      end
    end
  end
end
</code></pre>
<h3 id="stage-2-validation-and-security-checks">Stage 2: Validation and Security Checks</h3>
<p>Comprehensive validation using the validation engine:</p>
<pre><code class="language-ruby">def process_validated_file(temp_file, document_id, content_type, upload_result)
  # Stage 2: Validation and Security
  upload_result[:processing_stages] &lt;&lt; {
    stage: 'validation_security',
    started_at: Time.current,
    status: 'started'
  }

  begin
    validation_result = FileValidation::ValidationEngine.validate_file(
      temp_file, content_type
    )

    upload_result[:metadata].merge!(validation_result[:metadata])

    if validation_result[:valid]
      upload_result[:processing_stages].last[:status] = 'completed'
      upload_result[:processing_stages].last[:completed_at] = Time.current
      upload_result[:processing_stages].last[:validation_warnings] = validation_result[:warnings]

      # Proceed to metadata extraction
      metadata_result = extract_comprehensive_metadata(temp_file, content_type)
      upload_result[:metadata].merge!(metadata_result)

      # Proceed to permanent storage
      storage_result = move_to_permanent_storage(
        temp_file, document_id, content_type, upload_result[:metadata]
      )

      upload_result.merge!(storage_result)

    else
      upload_result[:errors] = validation_result[:errors]
      upload_result[:processing_stages].last[:status] = 'failed'
      upload_result[:processing_stages].last[:completed_at] = Time.current
    end

  rescue =&gt; e
    upload_result[:errors] &lt;&lt; {
      stage: 'validation',
      message: e.message
    }
    upload_result[:processing_stages].last[:status] = 'error'
    upload_result[:processing_stages].last[:completed_at] = Time.current
  end

  upload_result
end
</code></pre>
<h3 id="stage-3-metadata-extraction">Stage 3: Metadata Extraction</h3>
<p>Extract comprehensive metadata from different file types:</p>
<pre><code class="language-ruby">def extract_comprehensive_metadata(file, content_type)
  metadata = {
    extraction_timestamp: Time.current.iso8601,
    file_signature: calculate_file_signature(file),
    content_type_specific: {}
  }

  case content_type
  when 'document'
    metadata[:content_type_specific] = extract_document_metadata(file)
  when 'image'
    metadata[:content_type_specific] = extract_image_metadata(file)
  when 'audio'
    metadata[:content_type_specific] = extract_audio_metadata(file)
  end

  # Add processing hints for downstream jobs
  metadata[:processing_hints] = generate_processing_hints(file, content_type, metadata)

  metadata
end

def extract_document_metadata(file)
  mime_type = Marcel::MimeType.for(file)

  case mime_type
  when 'application/pdf'
    extract_pdf_metadata(file)
  when 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    extract_docx_metadata(file)
  when 'text/plain'
    extract_text_metadata(file)
  else
    { type: mime_type, basic_analysis: true }
  end
end

def extract_pdf_metadata(file)
  begin
    reader = PDF::Reader.new(file)

    {
      format: 'pdf',
      page_count: reader.page_count,
      pdf_version: reader.pdf_version,
      encrypted: reader.encrypted?,
      info: reader.info.to_h,
      estimated_word_count: estimate_pdf_word_count(reader),
      has_images: detect_pdf_images(reader),
      has_forms: detect_pdf_forms(reader),
      text_extractable: assess_pdf_text_extraction(reader)
    }
  rescue =&gt; e
    {
      format: 'pdf',
      error: &quot;Metadata extraction failed: #{e.message}&quot;,
      fallback_analysis: true
    }
  end
end

def extract_image_metadata(file)
  begin
    # Use ImageMagick or similar for comprehensive image analysis
    image_info = identify_image(file)

    {
      format: image_info[:format],
      dimensions: {
        width: image_info[:width],
        height: image_info[:height],
        aspect_ratio: calculate_aspect_ratio(image_info[:width], image_info[:height])
      },
      color_info: {
        bit_depth: image_info[:bit_depth],
        color_space: image_info[:color_space],
        has_transparency: image_info[:has_alpha],
        color_count: image_info[:colors]
      },
      technical: {
        compression: image_info[:compression],
        quality: image_info[:quality],
        file_size_efficiency: calculate_size_efficiency(image_info)
      },
      exif_data: extract_exif_data(file),
      processing_recommendations: generate_image_processing_recommendations(image_info)
    }
  rescue =&gt; e
    {
      format: 'unknown_image',
      error: &quot;Image analysis failed: #{e.message}&quot;,
      basic_analysis_only: true
    }
  end
end

def extract_audio_metadata(file)
  begin
    # Use audio analysis libraries
    audio_info = analyze_audio_file(file)

    {
      format: audio_info[:format],
      duration: audio_info[:duration],
      audio_properties: {
        sample_rate: audio_info[:sample_rate],
        channels: audio_info[:channels],
        bit_rate: audio_info[:bit_rate],
        bit_depth: audio_info[:bit_depth]
      },
      content_analysis: {
        has_speech: detect_speech_content(file),
        has_music: detect_music_content(file),
        silence_percentage: calculate_silence_percentage(file),
        volume_levels: analyze_volume_levels(file)
      },
      transcription_readiness: assess_transcription_feasibility(audio_info),
      id3_tags: extract_id3_tags(file)
    }
  rescue =&gt; e
    {
      format: 'unknown_audio',
      error: &quot;Audio analysis failed: #{e.message}&quot;,
      basic_analysis_only: true
    }
  end
end
</code></pre>
<h3 id="stage-4-content-processing-and-analysis">Stage 4: Content Processing and Analysis</h3>
<p>Initial content extraction and preparation:</p>
<pre><code class="language-ruby">def perform_initial_content_processing(file, content_type, metadata)
  processing_result = {
    content_extracted: false,
    content_preview: nil,
    processing_jobs_queued: [],
    analysis_metadata: {}
  }

  case content_type
  when 'document'
    processing_result.merge!(process_document_content(file, metadata))
  when 'image'
    processing_result.merge!(process_image_content(file, metadata))
  when 'audio'
    processing_result.merge!(process_audio_content(file, metadata))
  end

  processing_result
end

def process_document_content(file, metadata)
  begin
    # Extract text content immediately for preview
    extracted_text = extract_text_content(file, metadata[:content_type_specific][:format])

    {
      content_extracted: true,
      content_preview: extracted_text[0..500], # First 500 characters
      full_content_length: extracted_text.length,
      word_count: extracted_text.split.length,
      language_detected: detect_language(extracted_text),
      processing_jobs_queued: [
        'GenerateEmbeddings',
        'ExtractKeywords',
        'GenerateSummary'
      ]
    }
  rescue =&gt; e
    {
      content_extracted: false,
      extraction_error: e.message,
      processing_jobs_queued: ['ExtractText'] # Fallback to background extraction
    }
  end
end

def process_image_content(file, metadata)
  begin
    # Generate quick image description
    quick_description = generate_quick_image_description(file)

    {
      content_extracted: true,
      content_preview: quick_description,
      requires_ai_analysis: true,
      processing_jobs_queued: [
        'GenerateImageDescription',
        'ExtractImageText', # OCR if text detected
        'GenerateEmbeddings'
      ],
      analysis_metadata: {
        optimal_ai_model: recommend_vision_model(metadata),
        processing_priority: calculate_processing_priority(metadata)
      }
    }
  rescue =&gt; e
    {
      content_extracted: false,
      analysis_error: e.message,
      processing_jobs_queued: ['ProcessImageContent']
    }
  end
end

def process_audio_content(file, metadata)
  begin
    # Quick audio analysis
    audio_analysis = perform_quick_audio_analysis(file)

    {
      content_extracted: false, # Audio requires transcription
      content_preview: &quot;Audio file: #{metadata[:content_type_specific][:duration]}s duration&quot;,
      transcription_required: true,
      processing_jobs_queued: [
        'TranscribeAudio',
        'GenerateEmbeddings' # Will be queued after transcription
      ],
      analysis_metadata: {
        transcription_service: recommend_transcription_service(metadata),
        estimated_processing_time: estimate_transcription_time(metadata),
        language_hint: audio_analysis[:detected_language]
      }
    }
  rescue =&gt; e
    {
      content_extracted: false,
      analysis_error: e.message,
      processing_jobs_queued: ['ProcessAudioContent']
    }
  end
end
</code></pre>
<h3 id="stage-5-permanent-storage">Stage 5: Permanent Storage</h3>
<p>Move validated files to permanent storage:</p>
<pre><code class="language-ruby">def move_to_permanent_storage(temp_file, document_id, content_type, metadata)
  storage_result = {
    success: false,
    permanent_file_id: nil,
    storage_location: nil,
    storage_metadata: {}
  }

  begin
    # Determine optimal storage based on file characteristics
    target_storage = determine_optimal_storage(metadata, content_type)

    # Generate permanent file ID with organized structure
    permanent_id = generate_permanent_file_id(document_id, content_type, metadata)

    # Move file to permanent storage
    permanent_file = move_file_to_storage(temp_file, target_storage, permanent_id)

    storage_result.merge!({
      success: true,
      permanent_file_id: permanent_file.id,
      storage_location: target_storage,
      storage_metadata: {
        stored_at: Time.current.iso8601,
        storage_class: determine_storage_class(metadata),
        replication_status: 'pending',
        backup_scheduled: true
      }
    })

    # Schedule backup and replication
    schedule_file_backup(permanent_file, metadata)

    # Clean up temporary file
    cleanup_temp_file(temp_file)

  rescue =&gt; e
    storage_result[:error] = &quot;Storage failed: #{e.message}&quot;
  end

  storage_result
end

def determine_optimal_storage(metadata, content_type)
  file_size = metadata[:file_size]
  access_pattern = predict_access_pattern(metadata, content_type)

  case access_pattern
  when :frequent
    :hot_storage  # Fast, expensive storage
  when :occasional
    :warm_storage # Balanced cost/performance
  when :archive
    :cold_storage # Cheap, slower access
  else
    :standard_storage # Default
  end
end

def generate_permanent_file_id(document_id, content_type, metadata)
  # Organized file structure: type/year/month/document_id/hash
  date_path = Date.current.strftime(&quot;%Y/%m&quot;)
  file_hash = metadata[:file_signature][0..8] # First 8 chars of hash
  extension = extract_file_extension(metadata[:original_filename])

  &quot;#{content_type}/#{date_path}/#{document_id}/#{file_hash}#{extension}&quot;
end
</code></pre>
<h3 id="stage-6-database-record-creation">Stage 6: Database Record Creation</h3>
<p>Create database records with comprehensive metadata:</p>
<pre><code class="language-ruby">def create_database_records(document_id, content_type, file_info, metadata, processing_info)
  ActiveRecord::Base.transaction do
    # Find or create document
    document = Models::Document.find(document_id)

    # Create content record based on type
    content_record = create_content_record(
      document, content_type, file_info, metadata, processing_info
    )

    # Update document status and metadata
    update_document_with_file_info(document, content_record, metadata)

    # Queue background processing jobs
    queue_processing_jobs(content_record, processing_info[:processing_jobs_queued])

    {
      success: true,
      document_id: document.id,
      content_id: content_record.id,
      jobs_queued: processing_info[:processing_jobs_queued].length
    }
  end
rescue =&gt; e
  {
    success: false,
    error: &quot;Database record creation failed: #{e.message}&quot;
  }
end

def create_content_record(document, content_type, file_info, metadata, processing_info)
  content_class = case content_type
                  when 'document' then Models::TextContent
                  when 'image' then Models::ImageContent
                  when 'audio' then Models::AudioContent
                  else Models::Content
                  end

  content_attributes = {
    document: document,
    data: build_shrine_file_object(file_info),
    embedding_model: determine_embedding_model(content_type, metadata),
    metadata: build_content_metadata(metadata, processing_info)
  }

  # Add content-specific attributes
  case content_type
  when 'document'
    content_attributes[:content] = processing_info[:content_preview] if processing_info[:content_extracted]
  when 'image'
    content_attributes[:content] = processing_info[:content_preview] # Description
  when 'audio'
    # Content (transcript) will be added by background job
  end

  content_class.create!(content_attributes)
end

def build_shrine_file_object(file_info)
  {
    'id' =&gt; file_info[:permanent_file_id],
    'storage' =&gt; file_info[:storage_location].to_s,
    'metadata' =&gt; file_info[:storage_metadata].merge({
      'filename' =&gt; file_info[:original_filename],
      'mime_type' =&gt; file_info[:actual_mime_type],
      'size' =&gt; file_info[:file_size]
    })
  }
end

def queue_processing_jobs(content_record, job_names)
  job_names.each do |job_name|
    case job_name
    when 'GenerateEmbeddings'
      Ragdoll::Core::Jobs::GenerateEmbeddings.perform_later(content_record.document_id)
    when 'ExtractKeywords'
      Ragdoll::Core::Jobs::ExtractKeywords.perform_later(content_record.document_id)
    when 'GenerateSummary'
      Ragdoll::Core::Jobs::GenerateSummary.perform_later(content_record.document_id)
    when 'TranscribeAudio'
      # Custom job for audio transcription
      TranscribeAudioJob.perform_later(content_record.id)
    when 'GenerateImageDescription'
      # Custom job for image description
      GenerateImageDescriptionJob.perform_later(content_record.id)
    end
  end
end
</code></pre>
<h3 id="pipeline-monitoring-and-error-recovery">Pipeline Monitoring and Error Recovery</h3>
<pre><code class="language-ruby">module Ragdoll
  module Core
    class FileProcessingMonitor
      def self.monitor_processing_pipeline
        {
          active_uploads: count_active_uploads,
          processing_stages: analyze_processing_stages,
          error_rates: calculate_error_rates,
          throughput_metrics: calculate_throughput,
          storage_utilization: analyze_storage_usage
        }
      end

      def self.recover_failed_processing(document_id)
        document = Models::Document.find(document_id)

        # Analyze what went wrong
        failure_analysis = analyze_processing_failure(document)

        # Attempt recovery based on failure type
        case failure_analysis[:failure_type]
        when :validation_failure
          # Re-validate with updated rules
          retry_file_validation(document)
        when :storage_failure
          # Retry storage operation
          retry_file_storage(document)
        when :processing_timeout
          # Retry with extended timeout
          retry_processing_jobs(document, timeout: :extended)
        else
          # Manual intervention required
          flag_for_manual_review(document, failure_analysis)
        end
      end
    end
  end
end
</code></pre>
<h2 id="security-considerations">Security Considerations</h2>
<p>Ragdoll implements comprehensive security measures to protect against malicious files, unauthorized access, and data breaches throughout the file handling lifecycle.</p>
<h3 id="multi-layered-security-architecture">Multi-Layered Security Architecture</h3>
<pre><code class="language-mermaid">flowchart TD
    A[File Upload] --&gt; B[Input Validation]
    B --&gt; C[MIME Type Verification]
    C --&gt; D[Malware Scanning]
    D --&gt; E[Content Analysis]
    E --&gt; F[Access Control]
    F --&gt; G[Encryption at Rest]
    G --&gt; H[Secure URL Generation]
    H --&gt; I[Audit Logging]
</code></pre>
<h3 id="file-type-validation">File Type Validation</h3>
<p>Strict validation prevents malicious file uploads:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module Security
      class FileTypeValidator
        # Whitelist approach - only allow explicitly permitted file types
        ALLOWED_SIGNATURES = {
          # PDF files
          'application/pdf' =&gt; [
            ['%PDF-1.', 0], # PDF signature at start
          ],
          # DOCX files
          'application/vnd.openxmlformats-officedocument.wordprocessingml.document' =&gt; [
            ['PK', 0], # ZIP signature (DOCX is ZIP-based)
            ['[Content_Types].xml', 30..100] # DOCX-specific content
          ],
          # Image files
          'image/jpeg' =&gt; [
            ['\xFF\xD8\xFF', 0], # JPEG signature
          ],
          'image/png' =&gt; [
            ['\x89PNG\r\n\x1a\n', 0], # PNG signature
          ],
          # Audio files
          'audio/mpeg' =&gt; [
            ['ID3', 0], # MP3 with ID3 tag
            ['\xFF\xFB', 0], # MP3 without ID3
            ['\xFF\xF3', 0], # MP3 alternative
          ]
        }

        def self.validate_file_type(file)
          validation_result = {
            valid: false,
            detected_type: nil,
            security_issues: []
          }

          # Read file signature
          file_signature = read_file_signature(file, 256) # First 256 bytes

          # Detect actual file type by signature
          detected_type = detect_type_by_signature(file_signature)
          validation_result[:detected_type] = detected_type

          # Check against declared MIME type
          declared_type = file.content_type if file.respond_to?(:content_type)

          if declared_type &amp;&amp; declared_type != detected_type
            validation_result[:security_issues] &lt;&lt; {
              type: :mime_type_spoofing,
              severity: :high,
              message: &quot;Declared type #{declared_type} doesn't match detected type #{detected_type}&quot;
            }
          end

          # Validate against whitelist
          if ALLOWED_SIGNATURES.key?(detected_type)
            validation_result[:valid] = verify_file_signature(file_signature, detected_type)
          else
            validation_result[:security_issues] &lt;&lt; {
              type: :unsupported_file_type,
              severity: :critical,
              message: &quot;File type #{detected_type} is not allowed&quot;
            }
          end

          # Additional security checks
          validation_result[:security_issues].concat(perform_security_analysis(file))

          validation_result
        end

        private

        def self.read_file_signature(file, bytes = 256)
          file.rewind
          signature = file.read(bytes)
          file.rewind
          signature
        end

        def self.detect_type_by_signature(signature)
          ALLOWED_SIGNATURES.each do |mime_type, signatures|
            signatures.each do |sig_pattern, position|
              if position.is_a?(Range)
                # Check if pattern exists within range
                range_content = signature[position]
                return mime_type if range_content&amp;.include?(sig_pattern)
              else
                # Check exact position
                return mime_type if signature[position, sig_pattern.length] == sig_pattern
              end
            end
          end

          'application/octet-stream' # Unknown type
        end

        def self.perform_security_analysis(file)
          security_issues = []

          # Check for embedded executables
          if contains_embedded_executable?(file)
            security_issues &lt;&lt; {
              type: :embedded_executable,
              severity: :critical,
              message: &quot;File contains embedded executable content&quot;
            }
          end

          # Check for suspicious file patterns
          if suspicious_file_patterns?(file)
            security_issues &lt;&lt; {
              type: :suspicious_patterns,
              severity: :medium,
              message: &quot;File contains suspicious patterns&quot;
            }
          end

          # Check file size anomalies
          if unusual_file_size?(file)
            security_issues &lt;&lt; {
              type: :size_anomaly,
              severity: :low,
              message: &quot;File size is unusual for declared type&quot;
            }
          end

          security_issues
        end

        def self.contains_embedded_executable?(file)
          # Check for common executable signatures within the file
          executable_signatures = [
            'MZ',      # Windows PE
            '\x7fELF',  # Linux ELF
            '\xCE\xFA\xED\xFE', # Mach-O
            '\xFE\xED\xFA\xCE'  # Mach-O (reverse)
          ]

          file.rewind
          content = file.read
          file.rewind

          executable_signatures.any? { |sig| content.include?(sig) }
        end
      end
    end
  end
end
</code></pre>
<h3 id="malware-and-content-scanning">Malware and Content Scanning</h3>
<p>Integrated malware detection and content analysis:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module Security
      class MalwareScanner
        def self.scan_file(file)
          scan_results = {
            scanned: false,
            clean: false,
            threats_detected: [],
            scan_engines: []
          }

          # Multi-engine scanning approach
          scan_engines = configure_scan_engines

          scan_engines.each do |engine|
            begin
              engine_result = engine[:scanner].call(file)
              scan_results[:scan_engines] &lt;&lt; {
                name: engine[:name],
                result: engine_result,
                scanned_at: Time.current
              }

              if engine_result[:threats_detected]&amp;.any?
                scan_results[:threats_detected].concat(engine_result[:threats_detected])
              end

            rescue =&gt; e
              scan_results[:scan_engines] &lt;&lt; {
                name: engine[:name],
                error: e.message,
                scanned_at: Time.current
              }
            end
          end

          scan_results[:scanned] = scan_results[:scan_engines].any? { |e| !e[:error] }
          scan_results[:clean] = scan_results[:threats_detected].empty?

          # Quarantine file if threats detected
          if !scan_results[:clean]
            quarantine_file(file, scan_results[:threats_detected])
          end

          scan_results
        end

        private

        def self.configure_scan_engines
          engines = []

          # ClamAV integration
          if clamav_available?
            engines &lt;&lt; {
              name: 'ClamAV',
              priority: 1,
              scanner: method(:scan_with_clamav)
            }
          end

          # Custom pattern matching
          engines &lt;&lt; {
            name: 'PatternMatcher',
            priority: 2,
            scanner: method(:scan_with_patterns)
          }

          # Behavioral analysis
          engines &lt;&lt; {
            name: 'BehavioralAnalysis',
            priority: 3,
            scanner: method(:behavioral_scan)
          }

          engines
        end

        def self.scan_with_clamav(file)
          temp_file = create_temp_file_for_scanning(file)

          begin
            result = `clamscan --no-summary --infected #{temp_file.path} 2&gt;&amp;1`
            exit_code = $?.exitstatus

            scan_result = {
              engine: 'clamav',
              threats_detected: [],
              scan_output: result.strip
            }

            if exit_code == 1 # Virus found
              if match = result.match(/: (.+) FOUND$/)
                scan_result[:threats_detected] &lt;&lt; {
                  name: match[1],
                  type: 'virus',
                  severity: 'critical'
                }
              end
            elsif exit_code &gt; 1 # Scan error
              scan_result[:error] = &quot;ClamAV scan failed: #{result}&quot;
            end

            scan_result

          ensure
            temp_file&amp;.unlink
          end
        end

        def self.scan_with_patterns(file)
          # Custom malware signature patterns
          malware_patterns = [
            {
              pattern: /eval\s*\(\s*base64_decode/i,
              name: 'PHP Base64 Eval',
              type: 'webshell',
              severity: 'high'
            },
            {
              pattern: /&lt;script[^&gt;]*&gt;.*?(document\.write|eval|unescape).*?&lt;\/script&gt;/mi,
              name: 'Malicious JavaScript',
              type: 'script_injection',
              severity: 'high'
            },
            {
              pattern: /cmd\.exe|powershell\.exe|sh\s+-c/i,
              name: 'Command Execution',
              type: 'command_injection',
              severity: 'critical'
            }
          ]

          file.rewind
          content = file.read(10.megabytes) # Scan first 10MB
          file.rewind

          threats_detected = []

          malware_patterns.each do |pattern_info|
            if content.match?(pattern_info[:pattern])
              threats_detected &lt;&lt; {
                name: pattern_info[:name],
                type: pattern_info[:type],
                severity: pattern_info[:severity],
                detection_method: 'pattern_matching'
              }
            end
          end

          {
            engine: 'pattern_matcher',
            threats_detected: threats_detected
          }
        end

        def self.behavioral_scan(file)
          suspicious_behaviors = []

          # Analyze file entropy (high entropy might indicate encryption/packing)
          entropy = calculate_file_entropy(file)
          if entropy &gt; 7.5 # High entropy threshold
            suspicious_behaviors &lt;&lt; {
              name: 'High Entropy Content',
              type: 'suspicious_structure',
              severity: 'medium',
              details: { entropy: entropy }
            }
          end

          # Check for unusual file structure
          if unusual_file_structure?(file)
            suspicious_behaviors &lt;&lt; {
              name: 'Unusual File Structure',
              type: 'structural_anomaly',
              severity: 'low'
            }
          end

          {
            engine: 'behavioral_analysis',
            threats_detected: suspicious_behaviors.select { |b| b[:severity] == 'critical' },
            suspicious_behaviors: suspicious_behaviors
          }
        end

        def self.quarantine_file(file, threats)
          # Move file to quarantine location
          quarantine_id = SecureRandom.uuid
          quarantine_path = &quot;quarantine/#{Date.current.strftime('%Y/%m/%d')}/#{quarantine_id}&quot;

          # Store quarantine information
          quarantine_info = {
            id: quarantine_id,
            original_filename: file.original_filename,
            quarantined_at: Time.current,
            threats: threats,
            file_signature: calculate_file_hash(file)
          }

          # Log security incident
          log_security_incident('file_quarantined', quarantine_info)

          # Notify security team
          notify_security_team(quarantine_info)
        end
      end
    end
  end
end
</code></pre>
<h3 id="access-control-and-authorization">Access Control and Authorization</h3>
<p>Robust access control for file operations:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module Security
      class FileAccessControl
        def self.authorize_file_access(user, file, operation)
          authorization_result = {
            authorized: false,
            reason: nil,
            restrictions: []
          }

          # Check basic permissions
          base_permission = check_base_permission(user, operation)
          unless base_permission[:allowed]
            authorization_result[:reason] = base_permission[:reason]
            return authorization_result
          end

          # Check file-specific permissions
          file_permission = check_file_permission(user, file, operation)
          unless file_permission[:allowed]
            authorization_result[:reason] = file_permission[:reason]
            return authorization_result
          end

          # Check rate limits
          rate_limit_check = check_rate_limits(user, operation)
          if rate_limit_check[:exceeded]
            authorization_result[:reason] = 'Rate limit exceeded'
            authorization_result[:restrictions] &lt;&lt; rate_limit_check
            return authorization_result
          end

          # Check file access patterns
          access_pattern_check = analyze_access_pattern(user, file, operation)
          if access_pattern_check[:suspicious]
            # Log suspicious activity but allow access with monitoring
            log_suspicious_access(user, file, operation, access_pattern_check)
            authorization_result[:restrictions] &lt;&lt; {
              type: 'enhanced_monitoring',
              reason: access_pattern_check[:reason]
            }
          end

          authorization_result[:authorized] = true
          authorization_result
        end

        def self.generate_secure_file_url(file, user, options = {})
          # Generate time-limited, signed URLs for file access
          expires_at = options[:expires_at] || 1.hour.from_now

          # Create signature
          signature_data = {
            file_id: file.id,
            user_id: user&amp;.id,
            expires_at: expires_at.to_i,
            operation: options[:operation] || 'read'
          }

          signature = generate_url_signature(signature_data)

          # Build secure URL
          base_url = file.url
          query_params = {
            token: signature,
            expires: expires_at.to_i,
            user: user&amp;.id
          }.compact

          &quot;#{base_url}?#{query_params.to_query}&quot;
        end

        private

        def self.check_base_permission(user, operation)
          # Define operation permissions
          operation_permissions = {
            'read' =&gt; ['viewer', 'editor', 'admin'],
            'write' =&gt; ['editor', 'admin'],
            'delete' =&gt; ['admin'],
            'upload' =&gt; ['editor', 'admin']
          }

          required_roles = operation_permissions[operation] || []

          if user.nil?
            return { allowed: false, reason: 'Authentication required' }
          end

          unless required_roles.include?(user.role)
            return { 
              allowed: false, 
              reason: &quot;Insufficient permissions. Required: #{required_roles.join(', ')}&quot; 
            }
          end

          { allowed: true }
        end

        def self.check_file_permission(user, file, operation)
          # Check file-specific access rules

          # Personal files - only owner can access
          if file.metadata&amp;.dig('access_control', 'owner_only')
            file_owner_id = file.metadata.dig('access_control', 'owner_id')
            unless file_owner_id == user.id
              return { 
                allowed: false, 
                reason: 'File is private to owner only' 
              }
            end
          end

          # Restricted files - check explicit permissions
          if file.metadata&amp;.dig('access_control', 'restricted')
            allowed_users = file.metadata.dig('access_control', 'allowed_users') || []
            unless allowed_users.include?(user.id)
              return { 
                allowed: false, 
                reason: 'User not in file access list' 
              }
            end
          end

          # Quarantined files - admin only
          if file.metadata&amp;.dig('security', 'quarantined')
            unless user.role == 'admin'
              return { 
                allowed: false, 
                reason: 'File is quarantined - admin access only' 
              }
            end
          end

          { allowed: true }
        end

        def self.generate_url_signature(data)
          # Generate HMAC signature for URL security
          secret_key = ENV['RAGDOLL_URL_SIGNING_KEY'] || Rails.application.secret_key_base
          payload = data.to_json

          OpenSSL::HMAC.hexdigest('SHA256', secret_key, payload)
        end
      end
    end
  end
end
</code></pre>
<h3 id="encryption-at-rest">Encryption at Rest</h3>
<p>Comprehensive encryption for stored files:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module Security
      class FileEncryption
        def self.configure_encryption
          # S3 server-side encryption configuration
          if Shrine.storages[:store].is_a?(Shrine::Storage::S3)
            configure_s3_encryption
          end

          # Application-level encryption for sensitive files
          configure_application_encryption
        end

        def self.encrypt_sensitive_file(file)
          # Identify sensitive files that need application-level encryption
          return file unless requires_encryption?(file)

          # Generate file-specific encryption key
          encryption_key = generate_file_encryption_key

          # Encrypt file content
          encrypted_content = encrypt_content(file.read, encryption_key)

          # Store encryption metadata
          encryption_metadata = {
            encrypted: true,
            encryption_algorithm: 'AES-256-GCM',
            key_id: store_encryption_key(encryption_key),
            encrypted_at: Time.current.iso8601
          }

          # Create encrypted file object
          encrypted_file = StringIO.new(encrypted_content)
          encrypted_file.define_singleton_method(:metadata) do
            file.metadata.merge(encryption: encryption_metadata)
          end

          encrypted_file
        end

        def self.decrypt_file(encrypted_file)
          encryption_metadata = encrypted_file.metadata['encryption']
          return encrypted_file unless encryption_metadata&amp;.dig('encrypted')

          # Retrieve encryption key
          encryption_key = retrieve_encryption_key(encryption_metadata['key_id'])

          # Decrypt content
          decrypted_content = decrypt_content(
            encrypted_file.read, 
            encryption_key, 
            encryption_metadata['encryption_algorithm']
          )

          StringIO.new(decrypted_content)
        end

        private

        def self.configure_s3_encryption
          # Configure S3 server-side encryption
          s3_config = {
            server_side_encryption: 'AES256',
            # Or use KMS for additional key management
            # server_side_encryption: 'aws:kms',
            # ssekms_key_id: ENV['AWS_KMS_KEY_ID']
          }

          # Apply to storage configuration
          Shrine.storages[:store].instance_variable_get(:@s3).client.config.update(
            server_side_encryption: s3_config[:server_side_encryption]
          )
        end

        def self.requires_encryption?(file)
          # Determine if file needs application-level encryption
          sensitive_patterns = [
            /password/i,
            /confidential/i,
            /private/i,
            /secret/i,
            /ssn/i,
            /social.security/i
          ]

          filename = file.original_filename || ''
          content_sample = file.read(1024) # First 1KB
          file.rewind

          # Check filename
          return true if sensitive_patterns.any? { |pattern| filename.match?(pattern) }

          # Check content
          return true if sensitive_patterns.any? { |pattern| content_sample.match?(pattern) }

          false
        end

        def self.encrypt_content(content, key)
          cipher = OpenSSL::Cipher.new('AES-256-GCM')
          cipher.encrypt
          cipher.key = key

          iv = cipher.random_iv
          encrypted = cipher.update(content) + cipher.final
          tag = cipher.auth_tag

          # Combine IV, tag, and encrypted content
          [iv, tag, encrypted].map(&amp;:unpack1).join
        end

        def self.decrypt_content(encrypted_data, key, algorithm)
          # Split combined data
          iv_length = 12 # GCM IV length
          tag_length = 16 # GCM tag length

          iv = encrypted_data[0, iv_length]
          tag = encrypted_data[iv_length, tag_length]
          encrypted = encrypted_data[iv_length + tag_length..-1]

          # Decrypt
          decipher = OpenSSL::Cipher.new(algorithm)
          decipher.decrypt
          decipher.key = key
          decipher.iv = iv
          decipher.auth_tag = tag

          decipher.update(encrypted) + decipher.final
        end
      end
    end
  end
end
</code></pre>
<h3 id="security-audit-and-logging">Security Audit and Logging</h3>
<p>Comprehensive security monitoring and audit trails:</p>
<pre><code class="language-ruby">module Ragdoll
  module Core
    module Security
      class SecurityAuditor
        def self.log_file_operation(operation, file, user, result)
          audit_entry = {
            timestamp: Time.current.iso8601,
            operation: operation,
            file_id: file.id,
            file_path: file.metadata['filename'],
            user_id: user&amp;.id,
            user_ip: get_user_ip,
            result: result,
            metadata: {
              file_size: file.metadata['size'],
              mime_type: file.metadata['mime_type'],
              security_scan_result: file.metadata.dig('security', 'scan_result')
            }
          }

          # Log to security audit log
          write_security_log(audit_entry)

          # Send to SIEM if configured
          send_to_siem(audit_entry) if siem_configured?
        end

        def self.detect_anomalous_activity
          # Analyze recent file operations for suspicious patterns

          # Check for unusual upload volumes
          recent_uploads = count_recent_uploads(1.hour)
          if recent_uploads &gt; 100 # Threshold
            create_security_alert('high_upload_volume', {
              count: recent_uploads,
              threshold: 100,
              time_window: '1 hour'
            })
          end

          # Check for failed security scans
          failed_scans = count_failed_security_scans(24.hours)
          if failed_scans &gt; 5
            create_security_alert('multiple_security_failures', {
              count: failed_scans,
              time_window: '24 hours'
            })
          end

          # Check for unusual access patterns
          detect_unusual_access_patterns
        end

        private

        def self.write_security_log(entry)
          # Write to dedicated security log
          security_logger = Logger.new(
            ENV['SECURITY_LOG_PATH'] || 'log/security.log',
            formatter: proc { |severity, datetime, progname, msg|
              &quot;#{datetime.iso8601} #{severity} #{msg}\n&quot;
            }
          )

          security_logger.info(entry.to_json)
        end

        def self.create_security_alert(alert_type, details)
          alert = {
            id: SecureRandom.uuid,
            type: alert_type,
            severity: determine_alert_severity(alert_type),
            details: details,
            created_at: Time.current.iso8601,
            investigated: false
          }

          # Store alert
          store_security_alert(alert)

          # Notify security team
          notify_security_team(alert)
        end
      end
    end
  end
end
</code></pre>
<hr />
<h2 id="summary">Summary</h2>
<p>Ragdoll's file upload system provides enterprise-grade file handling through Shrine's flexible architecture. The system offers:</p>
<p><strong>Core Capabilities:</strong>
- <strong>Multi-Modal Support</strong>: Specialized handling for documents, images, and audio files
- <strong>Flexible Storage</strong>: Support for filesystem, S3, Google Cloud, and Azure backends
- <strong>Comprehensive Validation</strong>: Multi-layer security with MIME type verification and malware scanning
- <strong>Processing Pipeline</strong>: Automated content extraction and AI-powered analysis
- <strong>Security First</strong>: Encryption at rest, access control, and audit logging</p>
<p><strong>Supported File Types:</strong>
- <strong>Documents</strong>: PDF, DOCX, TXT, HTML, Markdown, JSON, RTF
- <strong>Images</strong>: JPEG, PNG, GIF, WebP, BMP, TIFF, SVG with AI description generation
- <strong>Audio</strong>: MP3, WAV, M4A, FLAC, OGG with automatic transcription</p>
<p><strong>Security Features:</strong>
- File signature validation and MIME type verification
- Integrated malware scanning with ClamAV and custom patterns
- Role-based access control with secure URL generation
- Application-level encryption for sensitive content
- Comprehensive audit logging and anomaly detection</p>
<p><strong>Production Ready:</strong>
- CDN integration for optimized delivery
- Hybrid storage strategies for cost optimization
- Automatic backup and replication
- Error recovery and processing monitoring
- Horizontal scaling with load balancing</p>
<p>The system seamlessly integrates with Ragdoll's document processing pipeline, ensuring secure, efficient file handling from upload through AI-powered content analysis and embedding generation.</p>
<p><em>This document is part of the Ragdoll documentation suite. For immediate help, see the <a href="../quick-start/">Quick Start Guide</a> or <a href="../api-client/">API Reference</a>.</em></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.50899def.min.js"></script>
      
    
  </body>
</html>